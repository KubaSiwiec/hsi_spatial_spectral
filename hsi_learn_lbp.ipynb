{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hsi_learn_lbp.ipynb",
      "provenance": [],
      "mount_file_id": "1Q5M1pnRzOaXu-p9oilJghoOflZnRMvFw",
      "authorship_tag": "ABX9TyONUQTbVPIWJ/nbkLZEs7MU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KubaSiwiec/hsi_spatial_spectral/blob/collab/hsi_learn_lbp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sXnDmXR7RDr2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "dfe044dd-0586-4887-d2e0-6bdbb1a2fef1"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5dWXpdkY4FNz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "feature extraction functions\n",
        "'''\n",
        "from IPython.display import clear_output\n",
        "import scipy.io\n",
        "from skimage.util import view_as_windows\n",
        "from skimage.util import pad\n",
        "import numpy as np\n",
        "from skimage.feature import local_binary_pattern, hog\n",
        "\n",
        "\n",
        "def get_data(file_name):\n",
        "    return scipy.io.loadmat(file_name)\n",
        "\n",
        "def get_patches(image, size = 3, use_padding = 'SAME'):\n",
        "\n",
        "    # add padding for image to make it able to extract the number of patches equal to number of pixels\n",
        "    # the pad width should eqal (patch size - 1) / 2,  - center pixel will always lay in original image\n",
        "    nb_padding_pixels = int(size/2 - 0.5)\n",
        "    # choose symmetric mode\n",
        "    image_padded = pad(image, nb_padding_pixels, 'symmetric')\n",
        "\n",
        "    patch_size = (size, size, image.shape[2])\n",
        "    patches = view_as_windows(image_padded, patch_size)[:, :, 0]\n",
        "    return patches\n",
        "\n",
        "def hsi_to_lbp(image, radius, n_points):\n",
        "\n",
        "    image_shape = image.shape\n",
        "    image_depth = image_shape[2]\n",
        "\n",
        "\n",
        "    lbp_map = np.zeros(image.shape)\n",
        "    \n",
        "    for k in range(image_depth):\n",
        "        # compare each pixel greyscale value with the central pixel\n",
        "        lbp_map[:, :, k] = local_binary_pattern(image[:, :, k], n_points, radius)\n",
        "\n",
        "    return lbp_map\n",
        "\n",
        "\n",
        "# def getCLBPlayer(image, radius):\n",
        "#     '''\n",
        "#     == Input ==\n",
        "#     gray_image  : color image of shape (height, width)\n",
        "    \n",
        "#     == Output ==  \n",
        "#     imgLBP : LBP converted image of the same shape as \n",
        "#     '''\n",
        "    \n",
        "\n",
        "#     imgCLBP = np.zeros(image.shape)\n",
        "#     img_mean = np.mean(image)\n",
        "#     radius = 3 \n",
        "#     for ih in range(0,image.shape[0] - radius):\n",
        "#         for iw in range(0,image.shape[1] - radius):\n",
        "#             ### Step 1: 3 by 3 pixel\n",
        "#             img = image[ih:ih+radius,iw:iw+radius]\n",
        "#             center = img[1,1]\n",
        "#             img01 = (img >= center)*1.0\n",
        "#             img01_vector = img01.T.flatten()\n",
        "#             # it is ok to order counterclock manner\n",
        "#             # img01_vector = img01.flatten()\n",
        "#             ### Step 2: **Binary operation**:\n",
        "#             img01_vector = np.delete(img01_vector,4)\n",
        "#             ### Step 3: Decimal: Convert the binary operated values to a digit.\n",
        "#             where_img01_vector = np.where(img01_vector)[0]\n",
        "#             # print(where_img01_vector)\n",
        "#             if len(where_img01_vector) >= 1:\n",
        "#                 num = np.sum(2**where_img01_vector)\n",
        "#             else:\n",
        "#                 num = 0\n",
        "#             imgCLBP[ih+1,iw+1] = num\n",
        "#     return(imgCLBP)\n",
        "\n",
        "def getCLBPlayer(image, radius):\n",
        "    '''\n",
        "    == Input ==\n",
        "    gray_image  : color image of shape (height, width)\n",
        "    \n",
        "    == Output ==  \n",
        "    imgLBP : LBP converted image of the same shape as \n",
        "    '''\n",
        "    \n",
        "\n",
        "    imgCLBP = np.zeros(image.shape)\n",
        "    img_mean = np.mean(image)\n",
        "    radius = 3 \n",
        "    for ih in range(0,image.shape[0] - radius):\n",
        "        for iw in range(0,image.shape[1] - radius):\n",
        "            ### Step 1: 3 by 3 pixel\n",
        "            img = image[ih:ih+radius,iw:iw+radius]\n",
        "            center = img[1,1]\n",
        "            # img01 = (img - center >= img_mean/2)*1.0\n",
        "            S_map = (img >= center)*1.0\n",
        "            M_map = (img - center >= img_mean/2)*1.0\n",
        "            S_vector = S_map.T.flatten()\n",
        "            M_vector = M_map.T.flatten()\n",
        "            # it is ok to order counterclock manner\n",
        "            # img01_vector = img01.flatten()\n",
        "            ### Step 2: **Binary operation**:\n",
        "            S_vector = np.delete(S_vector,4)\n",
        "            M_vector = np.delete(M_vector,4)\n",
        "            ### Step 3: Decimal: Convert the binary operated values to a digit.\n",
        "            CLBP_vector = np.insert(S_vector, np.arange(len(M_vector)), M_vector)\n",
        "            where_CLBP_vector = np.where(CLBP_vector)[0]\n",
        "            # print(where_CLBP_vector)\n",
        "            if len(where_CLBP_vector) >= 1:\n",
        "                num = np.sum(2**where_CLBP_vector)\n",
        "            else:\n",
        "                num = 0\n",
        "            imgCLBP[ih+1,iw+1] = num\n",
        "    return(imgCLBP)\n",
        "\n",
        "def hsi_to_clbp(image, radius):\n",
        "\n",
        "    image_shape = image.shape\n",
        "    image_depth = image_shape[2]\n",
        "\n",
        "\n",
        "    clbp_map = np.zeros(image.shape)\n",
        "    \n",
        "    for k in range(image_depth):\n",
        "        clear_output()\n",
        "        print(\"Progress -> {}%\".format(k/image_depth * 100))\n",
        "        # compare each pixel greyscale value with the central pixel\n",
        "        clbp_map[:, :, k] = getCLBPlayer(image[:, :, k], radius)\n",
        "\n",
        "    return clbp_map\n",
        "\n",
        "\n",
        "def hsi_to_hog(image, radius):\n",
        "\n",
        "    image_shape = image.shape\n",
        "    image_depth = image_shape[2]\n",
        "\n",
        "    hog_lst = []\n",
        "    \n",
        "    for k in range(image_depth):\n",
        "        # compare each pixel greyscale value with the central pixel\n",
        "        hog_lst.append(hog(image[:, :, k]))\n",
        "\n",
        "    hog_arr = np.asarray(hog_lst)\n",
        "\n",
        "    return hog_arr\n",
        "\n",
        "\n",
        "def hsi_to_wtf(image):\n",
        "\n",
        "    image_shape = image.shape\n",
        "    image_width = image_shape[0]\n",
        "    image_height = image_shape[1]\n",
        "    image_depth = image_shape[2]\n",
        "\n",
        "    # print(\"Shape: {}, Width: {}, Height: {}, Depth: {}\".format(image_shape, image_width, image_height, image_depth))\n",
        "\n",
        "    #get the image shape\n",
        "    central_pixel = image[int((image_width - 1) / 2), int((image_height - 1) / 2), :]\n",
        "\n",
        "    # print(\"Central pixel: {}\".format(central_pixel))\n",
        "\n",
        "    lbp_map = np.zeros(image.shape)\n",
        "    # dimensions of the image: (image_width,image_height,image_depth)\n",
        "    # for each of k channels\n",
        "    for k in range(image_depth):\n",
        "        # compare each pixel greyscale value with the central pixel\n",
        "        for i in range(image_width):\n",
        "            for j in range(image_height):\n",
        "                if image[i,j,k] >= central_pixel[k]:\n",
        "                    lbp_map[i,j,k] = True\n",
        "                elif image[i,j,k] < central_pixel[k]:\n",
        "                    lbp_map[i,j,k] = False\n",
        "                # setting the central pixel to 0.5 removes the noisy pixel from the middle of a image\n",
        "                #but LBP map stops to be binary\n",
        "                #when using it, remove the eqaul sign from the first conditional equation\n",
        "                # else:\n",
        "                #     lbp_map[i,j,k] = 0.5\n",
        "\n",
        "    print('lbp map: {}'.format(lbp_map))\n",
        "\n",
        "    return lbp_map\n",
        "\n",
        "\n",
        "def hsi_to_mwtf(image):\n",
        "    #here, the treshold will be set as mean of the image, not as value of specific central pixel\n",
        "\n",
        "    image_shape = image.shape\n",
        "    image_width = image_shape[0]\n",
        "    image_height = image_shape[1]\n",
        "    image_depth = image_shape[2]\n",
        "\n",
        "    # print(\"Shape: {}, Width: {}, Height: {}, Depth: {}\".format(image_shape, image_width, image_height, image_depth))\n",
        "\n",
        "    #get the image shape\n",
        "    central_pixel = image[int((image_width - 1) / 2), int((image_height - 1) / 2), :]\n",
        "\n",
        "    # print(\"Central pixel: {}\".format(central_pixel))\n",
        "\n",
        "    clbp_map = np.zeros(image.shape)\n",
        "    # dimensions of the image: (image_width,image_height,image_depth)\n",
        "    # for each of k channels\n",
        "    for k in range(image_depth):\n",
        "        # compare each pixel greyscale value with the mean of the image\n",
        "\n",
        "        #get mean of a layer\n",
        "        channel_mean = np.mean(image[:, :, k])\n",
        "        for i in range(image_width):\n",
        "            for j in range(image_height):\n",
        "                if image[i,j,k] >= channel_mean:\n",
        "                    clbp_map[i,j,k] = 1\n",
        "                elif image[i,j,k] < channel_mean:\n",
        "                    clbp_map[i,j,k] = 0\n",
        "\n",
        "    return clbp_map\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def hs_to_grey(image):\n",
        "    return np.mean(image, axis = 2)\n",
        "\n",
        "def arr2D_to_list(arr: np.array):\n",
        "    dims = len(arr.shape)\n",
        "    lst = []\n",
        "    if dims == 2:\n",
        "        print('Gt width: {}, length: {}'.format(arr.shape[0], arr.shape[1]))\n",
        "        for i in range(arr.shape[0]):\n",
        "            for j in range(arr.shape[1]):\n",
        "                lst.append(arr[i, j])\n",
        "\n",
        "        return lst\n",
        "    else:\n",
        "        raise Exception('Array should be two dimentional')\n",
        "\n",
        "def arr5D_to_list_of_3D_arr(arr: np.array):\n",
        "    dims = len(arr.shape)\n",
        "    lst = []\n",
        "    if dims == 5:\n",
        "        for i in range(arr.shape[0]):\n",
        "            for j in range(arr.shape[1]):\n",
        "                    lst.append(arr[i, j])\n",
        "        return lst\n",
        "    else:\n",
        "        raise Exception('Array should be two dimentional')\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g9aqlGP74MAJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "create CNN model function\n",
        "'''\n",
        "from tensorflow import keras\n",
        "\n",
        "# model definition function\n",
        "def create_model_CNN(l2_loss_lambda = None):\n",
        "    keras.backend.clear_session()\n",
        "\n",
        "    target_size = (32, 32)\n",
        "    l2 = None if l2_loss_lambda is None else keras.regularizers.l2(l2_loss_lambda)\n",
        "    if l2 is not None:\n",
        "        print('Using L2 regularization - l2_loss_lambda = %.4f' % l2_loss_lambda)\n",
        "\n",
        "    model = keras.Sequential(\n",
        "        [\n",
        "            keras.layers.Lambda(lambda image: tf.image.resize(image, target_size)),\n",
        "            keras.layers.Conv2D(256, 3, activation=tf.nn.relu, input_shape=(32, 32, 103)),\n",
        "            keras.layers.MaxPool2D(2),\n",
        "            keras.layers.Conv2D(512, 3, activation=tf.nn.relu),\n",
        "            keras.layers.MaxPool2D(2),\n",
        "            keras.layers.Flatten(),\n",
        "            keras.layers.Dropout(0.4),\n",
        "            keras.layers.Dense(512, activation=tf.nn.relu, kernel_regularizer=l2),\n",
        "            keras.layers.Dropout(0.4),\n",
        "            keras.layers.Dense(10, activation=tf.nn.softmax),\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    # model compiling\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"]\n",
        "    )\n",
        "\n",
        "    return model"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PYjV6R59l55d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import gc\n",
        "class GarbageCollectorCallback(tf.keras.callbacks.Callback):\n",
        "\n",
        "  def on_epoch_end(self, epoch, logs=None):\n",
        "    gc.collect()\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D9yw3o594TxW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from skimage.transform import resize\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ZrPJE13RRXU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "6c5139ab-a80e-4b2a-bc5e-73665dc3ddb4"
      },
      "source": [
        "mat = get_data(\"/content/drive/My Drive/PaviaU.mat\")\n",
        "# print(mat)\n",
        "\n",
        "mat_gt = get_data(\"/content/drive/My Drive/PaviaU_gt.mat\")\n",
        "# print(mat_gt\n",
        "\n",
        "data = mat['paviaU']\n",
        "ground_truth = mat_gt['paviaU_gt']\n",
        "\n",
        "print(\"Shape of the cube: {}\".format(data.shape))\n",
        "print(\"Shape of the labels_arr: {}\".format(ground_truth.shape))\n",
        "print(\"Number of classes: {}\".format(np.unique(ground_truth)))\n",
        "\n",
        "print(\"Maximum value: {}\".format(np.argmax(data)))\n",
        "\n",
        "print(\"Index of maximum value: {}\".format(np.unravel_index(np.argmax(data), data.shape)))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of the cube: (610, 340, 103)\n",
            "Shape of the labels_arr: (610, 340)\n",
            "Number of classes: [0 1 2 3 4 5 6 7 8 9]\n",
            "Maximum value: 396299\n",
            "Index of maximum value: (11, 107, 58)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9UiL9rpFUZY7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "outputId": "7fac78bb-d06e-42ef-b19e-a2017bc294e1"
      },
      "source": [
        "mat = get_data(\"/content/drive/My Drive/PaviaU.mat\")\n",
        "\n",
        "mat_gt = get_data(\"/content/drive/My Drive/PaviaU_gt.mat\")\n",
        "\n",
        "mat_training = get_data(\"/content/drive/My Drive/PaviaU_tr.mat\")\n",
        "\n",
        "\n",
        "data = mat['paviaU']\n",
        "ground_t = mat_gt['paviaU_gt']\n",
        "ground_truth = ground_t.flatten()\n",
        "training_data_full = mat_training['PaviaUni_train'].flatten()\n",
        "\n",
        "training_indeces = np.asarray(np.where(training_data_full > 0))\n",
        "testing_indices = np.asarray(np.where(ground_truth > 0))\n",
        "\n",
        "training_labels = np.take(training_data_full, training_indeces, axis = 0).flatten()\n",
        "testing_labels = np.take(ground_truth, testing_indices, axis = 0).flatten()\n",
        "\n",
        "\n",
        "print(\"Shape of the cube: {}\".format(data.shape))\n",
        "print(\"Shape of the labels_array: {}\".format(ground_truth.shape))\n",
        "print(\"Shape of training labels array: {}\".format(training_data_full.shape))\n",
        "print(\"Shape of training indeces array: {}\".format(training_indeces.shape))\n",
        "print(\"Training labels classes: {}\".format(np.unique(training_labels)))\n",
        "print(\"Number of classes: {}\".format(np.unique(ground_truth)))\n",
        "print(\"Shape of testing indices array: {}\".format(testing_indices.shape))\n",
        "print(\"Shape of testing labels array: {}\".format(testing_labels.shape))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(\"Maximum value: {}\".format(np.argmax(data)))\n",
        "\n",
        "print(\"Index of maximum value: {}\".format(np.unravel_index(np.argmax(data), data.shape)))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of the cube: (610, 340, 103)\n",
            "Shape of the labels_array: (207400,)\n",
            "Shape of training labels array: (207400,)\n",
            "Shape of training indeces array: (1, 3921)\n",
            "Training labels classes: [1 2 3 4 5 6 7 8 9]\n",
            "Number of classes: [0 1 2 3 4 5 6 7 8 9]\n",
            "Shape of testing indices array: (1, 42776)\n",
            "Shape of testing labels array: (42776,)\n",
            "Maximum value: 396299\n",
            "Index of maximum value: (11, 107, 58)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LNe_VQtPRR2U",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "41184b63-32af-4705-cc91-ebb5b0303d6f"
      },
      "source": [
        "# apply lbp and clbp on image\n",
        "radius = 3\n",
        "processed_image = hsi_to_clbp(data, radius)\n",
        "print('CLBP image shape: {}'.format(processed_image.shape))\n",
        "print(np.int_(processed_image/10000))\n",
        "\n",
        "processed_image = np.int_(processed_image/np.max(processed_image)*65535)\n",
        "print(np.max(processed_image))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Progress -> 3.8834951456310676%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t6lMXbqaRSSw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#crop patches\n",
        "patch_size = 19\n",
        "data_patches = get_patches(processed_image, patch_size)\n",
        "print('CLBP patches shape: {}'.format(data_patches.shape))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AACdpxWCiEZG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pip install spectral"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PyWC2kv0d1_k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import spectral\n",
        "spectral.imshow(data, [30, 51, 72])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RuZ4tdxiUOv3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "spectral.imshow(processed_image, [0, 51, 102])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QcVarj8CRrVi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "Plotting images\n",
        "'''\n",
        "\n",
        "#compare greyscale image with lbp map\n",
        "plt.figure(1)\n",
        "plt.imshow(hs_to_grey(data), cmap='gray')\n",
        "plt.title(\"Grayscale image\")\n",
        "\n",
        "plt.figure(2)\n",
        "plt.imshow(hs_to_grey(processed_image), cmap='gray')\n",
        "plt.title(\"CLBP image\")\n",
        "\n",
        "# present some patches of lbp data\n",
        "plt.figure(4)\n",
        "co_x = 100\n",
        "co_y = 100\n",
        "plt.imshow(hs_to_grey(data_patches[co_x, co_y]), cmap='gray')\n",
        "plt.title(\"CLBP sample patch of coordinates {}, {}\".format(co_x, co_y))\n",
        "\n",
        "# plt.figure(6)\n",
        "# plt.imshow(ground_truth)\n",
        "# plt.title('Classes')\n",
        "\n",
        "plt.show()\n",
        "\n",
        "# #free memory\n",
        "# data = None\n",
        "# processed_image = None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IX2RW965d7kC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "spectral.imshow(data_patches[co_x, co_y])\n",
        "co_x = None\n",
        "co_y = None\n",
        "gc.collect()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fFhQFkJMRzDN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "Save patches and ground truth into arrays\n",
        "'''\n",
        "\n",
        "# patches\n",
        "# patch_arr = np.asarray(arr5D_to_list_of_3D_arr(data_patches), dtype=np.uint8)\n",
        "training_patch_arr = np.resize(np.take(np.asarray(arr5D_to_list_of_3D_arr(data_patches), dtype=np.uint8), training_indeces, axis = 0), (training_labels.shape[0], patch_size, patch_size, 103))\n",
        "testing_patch_arr = np.resize(np.take(np.asarray(arr5D_to_list_of_3D_arr(data_patches), dtype=np.uint8), testing_indices, axis = 0), (testing_labels.shape[0], patch_size, patch_size, 103))\n",
        "\n",
        "print(testing_patch_arr.shape)\n",
        "print('patch_lbp_list len: {}'.format(training_patch_arr.shape))\n",
        "data_patches = None\n",
        "gc.collect()\n",
        "\n",
        "# ground truth\n",
        "labels_gt = ground_truth.flatten()\n",
        "print(\"Labels len: {}\".format(len(labels_gt)))\n",
        "print(np.unique(labels_gt))\n",
        "ground_truth = None\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vei-cPSCR611",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "split data to training and validation datasets\n",
        "'''\n",
        "gc.collect()\n",
        "\n",
        "val_split = 0.12\n",
        "# X_train, X_val, y_train, y_val = train_test_split(training_patch_arr, training_labels, test_size=val_split, stratify=training_labels)\n",
        "X_train, X_val, y_train, y_val = train_test_split(testing_patch_arr, testing_labels, test_size=val_split, stratify=testing_labels)\n",
        "\n",
        "#free memory\n",
        "# patches_sequence = None\n",
        "label_gt = None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hNLGGMCmSRB5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "Create and fit model, get loss, accuracy and f1-score metrics\n",
        "'''\n",
        "model = create_model_CNN(0.01)\n",
        "\n",
        "gc.collect()\n",
        "history = model.fit(X_train, y_train, batch_size = 128, epochs=20, validation_data=(X_val, y_val))\n",
        "print(model.summary())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HKVY1RU10fZo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "Plot accuracy\n",
        "'''\n",
        "\n",
        "plt.figure(1)\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.legend(['train accuracy', 'val accuracy'])\n",
        "plt.title(\"LBP, CNN, {}x{} patch\".format(patch_size, patch_size))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p7FBRIr29Bv-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "get predictions and predicted labels\n",
        "'''\n",
        "\n",
        "predictions = model.predict(X_val)\n",
        "gt_predicted = [np.argmax(prediction) for prediction in predictions]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RLkXzHZBn0E3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "Calculate kappa coefictient\n",
        "'''\n",
        "\n",
        "from sklearn.metrics import cohen_kappa_score, f1_score\n",
        "\n",
        "kappa = cohen_kappa_score(y_val, np.array(gt_predicted))\n",
        "f1 = f1_score(y_val, np.array(gt_predicted), average = 'weighted')\n",
        "print(\"Kappa: {}, F1: {}\".format(kappa, f1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fNN-dMheXRKW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# predictions_test = model.predict(testing_patch_arr)\n",
        "predictions_test = model.predict(training_patch_arr)\n",
        "gt_predicted_test = [np.argmax(prediction) for prediction in predictions_test]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M8fRrLM2dLyV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# result = model.evaluate(testing_patch_arr, testing_labels)\n",
        "\n",
        "# kappa_test = cohen_kappa_score(testing_labels, np.array(gt_predicted_test))\n",
        "# f1_test = f1_score(testing_labels, np.array(gt_predicted_test), average = 'weighted')\n",
        "# print(\"Testing accuracy: {}\\nKappa: {}\\nF1: {}\".format(result,kappa_test, f1_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cebny11hlET7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "result = model.evaluate(training_patch_arr, training_labels)\n",
        "\n",
        "kappa_test = cohen_kappa_score(training_labels, np.array(gt_predicted_test))\n",
        "f1_test = f1_score(training_labels, np.array(gt_predicted_test), average = 'weighted')\n",
        "print(\"Testing loss and accuracy: {}\\nKappa: {}\\nF1: {}\".format(result,kappa_test, f1_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H74wkNwAwlet",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import os, sys\n",
        "# sys.path.append(os.path.join(os.getcwd(), \"keras-deep-graph-learning\")) # Adding the submodule to the module search path\n",
        "# sys.path.append(os.path.join(os.getcwd(), \"keras-deep-graph-learning/examples\")) # Adding the submodule to the module search path\n",
        "# import numpy as np\n",
        "# from keras.layers import Dense, Activation, Dropout\n",
        "# from keras.models import Model, Sequential\n",
        "# from keras.regularizers import l2\n",
        "# from keras.optimizers import Adam\n",
        "# from keras_dgl.layers import GraphCNN\n",
        "# import keras.backend as K\n",
        "# from keras.utils import to_categorical\n",
        "\n",
        "# print(\"Creating our simple sample data...\")\n",
        "# A = np.array([[0,1,5], [1,0,0], [5,0,0]])\n",
        "# print(A)\n",
        "# X = np.array([[1,2,10], [4,3,10], [0,2,11]]) # features, whatever we have there...\n",
        "\n",
        "# # Notice, if we set A = identity matrix, then we'd effectively assume no edges and just do a basic\n",
        "# # MLP on the features.\n",
        "\n",
        "# # We could do the same by setting the graph_conv_filter below to Id.\n",
        "\n",
        "# # We could also set X to Id, and thus effectively assume no features, and in this way\n",
        "# # do an \"edge\" embedding, so effectively try to understand what's connected to what.\n",
        "\n",
        "# # We could then use that as feature in any way we like...\n",
        "\n",
        "# Y_o_dim = np.array([1,2,1])\n",
        "# Y =  to_categorical(Y_o_dim) # labels, whatever we wanna classify things into... in categorical form."
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}